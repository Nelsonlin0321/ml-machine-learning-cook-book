{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Transformer-based recommendation system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.dataset import RatingDataset\n",
    "from src import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group_id_map_dict = utils.open_object(\"./artifacts/age_group_id_map_dict.pkl\")\n",
    "\n",
    "movie_id_map_dict = utils.open_object(\"./artifacts/movie_id_map_dict.pkl\")\n",
    "\n",
    "occupation_id_map_dict = utils.open_object(\"./artifacts/occupation_id_map_dict.pkl\")\n",
    "\n",
    "sex_id_map_dict = utils.open_object(\"./artifacts/sex_id_map_dict.pkl\")\n",
    "\n",
    "user_id_map_dict = utils.open_object(\"./artifacts/user_id_map_dict.pkl\")\n",
    "# genres_map_dict = utils.open_object(\"./artifacts/genres_map_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_min_max_scaler = utils.open_object(\"./artifacts/rating_min_max_scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_user = len(user_id_map_dict)\n",
    "num_movie = len(movie_id_map_dict)\n",
    "num_occupation = len(occupation_id_map_dict)\n",
    "num_age_group = len(age_group_id_map_dict)\n",
    "# num_genre = len(genres_map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_configs = {}\n",
    "EMED_DIM=32\n",
    "sequence_length=4\n",
    "embed_configs['user']={\"embed_dim\":EMED_DIM,\"num_embed\":num_user}\n",
    "embed_configs['movie']={\"embed_dim\":EMED_DIM,\"num_embed\":num_movie}\n",
    "embed_configs['occupation']={\"embed_dim\":EMED_DIM,\"num_embed\":num_occupation}\n",
    "embed_configs['age_group']={\"embed_dim\":EMED_DIM,\"num_embed\":num_age_group}\n",
    "embed_configs['position'] = {\"embed_dim\":EMED_DIM,\"num_embed\":sequence_length}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict={}\n",
    "config_dict['embed_configs'] = embed_configs\n",
    "config_dict['transformer_num_layer']=3\n",
    "config_dict['dropout']=0.2\n",
    "config_dict['epoches']=6\n",
    "config_dict['learning_rate']=0.001\n",
    "config_dict['batch_size']=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, dictionary):\n",
    "        for key, value in dictionary.items():\n",
    "            setattr(self, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(dictionary=config_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user': {'embed_dim': 32, 'num_embed': 6041},\n",
       " 'movie': {'embed_dim': 32, 'num_embed': 3884},\n",
       " 'occupation': {'embed_dim': 32, 'num_embed': 22},\n",
       " 'age_group': {'embed_dim': 32, 'num_embed': 8},\n",
       " 'position': {'embed_dim': 32, 'num_embed': 4}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.embed_configs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Load Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import BSTRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BSTRecommender(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func = nn.MSELoss()\n",
    "loss_func = nn.L1Loss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"./artifacts/train_data.parquet\")\n",
    "df_test = pd.read_parquet(\"./artifacts/test_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = RatingDataset(data=df_train) \n",
    "test_dataset = RatingDataset(data=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=config.batch_size,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=config.batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1166/1166 [00:05<00:00, 199.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24997990546463694}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "before_training_metrics = evaluate(model,test_loader,loss_func=loss_func)\n",
    "print(before_training_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=config.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = 0\n",
    "best_eval_loss =  float(\"inf\")\n",
    "best_checkpoint = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version='v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.eval_steps = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1166/1166 [00:06<00:00, 186.82it/s]81.10it/s]\n",
      "100%|██████████| 1166/1166 [00:06<00:00, 193.87it/s]78.41it/s, eval_loss=0.187, best_eval_loss=0.187, train_loss=0.195, steps=2000, best_checkpoint=2000]  \n",
      "100%|██████████| 1166/1166 [00:06<00:00, 178.05it/s]84.25it/s, eval_loss=0.182, best_eval_loss=0.182, train_loss=0.188, steps=4000, best_checkpoint=4000]  \n",
      " 81%|████████  | 945/1166 [00:05<00:01, 197.15it/s] 82.32it/s, eval_loss=0.178, best_eval_loss=0.178, train_loss=0.185, steps=6000, best_checkpoint=6000]  "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "total_pbar = tqdm(total=len(train_loader)*config.epoches,\n",
    "                  desc=\"Training\", position=0, leave=True)\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for epoch in range(config.epoches):\n",
    "    # print(\"*\"*50 + f\"epoch: {epoch + 1}\" + \"*\"*50)\n",
    "\n",
    "    train_loss_list = []\n",
    "    prob_list = []\n",
    "    rating_list = []\n",
    "\n",
    "    for inputs in train_loader:\n",
    "        model = model.train()\n",
    "        optimizer.zero_grad()\n",
    "        probs = model(inputs)\n",
    "\n",
    "        rating = inputs['target_rating'].view(-1, 1)\n",
    "\n",
    "        loss = loss_func(probs, rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        probs = probs.detach().cpu().numpy().flatten().tolist()\n",
    "        prob_list.extend(probs)\n",
    "        rating = rating.numpy().flatten().tolist()\n",
    "        rating_list.extend(rating)\n",
    "\n",
    "        if (total_batch+1) % config.eval_steps == 0:\n",
    "\n",
    "            improve = False\n",
    "            model_metrics = evaluate(model, test_loader)\n",
    "            eval_loss = model_metrics['eval_loss']\n",
    "\n",
    "            if eval_loss <= best_eval_loss:\n",
    "                improve = True\n",
    "                best_checkpoint = total_batch+1\n",
    "                best_eval_loss = eval_loss\n",
    "\n",
    "            train_loss = np.mean(train_loss_list)\n",
    "            \n",
    "            model_metrics['best_eval_loss'] = best_eval_loss\n",
    "            model_metrics['train_loss'] = train_loss\n",
    "            model_metrics[\"steps\"] = total_batch+1\n",
    "            model_metrics[\"best_checkpoint\"] = best_checkpoint\n",
    "            metrics_list.append(model_metrics)\n",
    "                \n",
    "            if improve:\n",
    "                save_dir = os.path.join(\"model\", model_version)\n",
    "                os.makedirs(save_dir, exist_ok=True)\n",
    "                model_path = utils.save_model(model, save_dir, total_batch+1, model_metrics)\n",
    "            \n",
    "            post_fix_message = {k:round(v,3) for k,v in model_metrics.items()}\n",
    "            total_pbar.set_postfix(post_fix_message)\n",
    "\n",
    "\n",
    "            model = model.train()\n",
    "\n",
    "        total_batch += 1\n",
    "        total_pbar.update(1)\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "total_pbar.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
